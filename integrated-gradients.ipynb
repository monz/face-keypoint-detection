{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect Model with Integrated Gradient\n",
    "\n",
    "https://www.tensorflow.org/tutorials/interpretability/integrated_gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration for notebook\n",
    "IN_COLAB = False\n",
    "USE_GPU = IN_COLAB and False  # TPU and GPU only available in COLAB environment\n",
    "USE_TPU = IN_COLAB and ((not USE_GPU) ^ False)  # XOR; either use GPU or TPU, cannot use both at the same time\n",
    "\n",
    "BASE_PATH = '.'\n",
    "LOG_DIR = os.path.join(BASE_PATH, 'logs')\n",
    "USE_RGB = False\n",
    "\n",
    "if USE_RGB:\n",
    "    MODEL_OUTPUT_DIR = os.path.join(BASE_PATH, 'face_keypoint_model_rgb')\n",
    "    INPUT_CHANNEL_COUNT = 3  # test with gray-scale to rgb \n",
    "else:\n",
    "    MODEL_OUTPUT_DIR = os.path.join(BASE_PATH, 'face_keypoint_model')\n",
    "    INPUT_CHANNEL_COUNT = 1  # due to gray-scale image we have only one color channel\n",
    "\n",
    "# load pre-trained model or train new model\n",
    "if os.path.exists(MODEL_OUTPUT_DIR):\n",
    "    model = keras.models.load_model(MODEL_OUTPUT_DIR)\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "TEST_DATA_FILE = os.path.join(BASE_PATH, 'data', 'test.csv')\n",
    "\n",
    "# read raw data from csv\n",
    "test_data_raw = pd.read_csv(TEST_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_str_to_image(string_list):\n",
    "    return np.array([np.array(row.split(), dtype=np.uint8) for row in string_list])\n",
    "\n",
    "\n",
    "def normalize_image(data, width, height, channel_count):\n",
    "    return (data / 255.0).reshape((width, height, channel_count)) # no batch layer\n",
    "\n",
    "\n",
    "def normalize_image_batch(data, width, height, channel_count):\n",
    "    return (data / 255.0).reshape((-1, width, height, channel_count)) # additional batch layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define test image\n",
    "image_index = 994\n",
    "\n",
    "# prepare test data for prediction\n",
    "# convert image string to Numpy array\n",
    "test_data = from_str_to_image(test_data_raw['Image'])\n",
    "if USE_RGB:\n",
    "    # re-create rgb channels from gray-scale\n",
    "    test_data = np.stack((test_data,)*3, axis=-1)\n",
    "\n",
    "# extract image dimensions\n",
    "IMG_WIDTH = IMG_HEIGHT = np.sqrt(test_data.shape[1]).astype(np.uint8)\n",
    "\n",
    "# show first test image\n",
    "plt.imshow(test_data[image_index, :].reshape((IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction test for RGB image variant\n",
    "test_image = test_data[image_index, :]\n",
    "\n",
    "print(test_image.shape)\n",
    "normalized_img = normalize_image_batch(test_image, IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT)\n",
    "print(normalized_img.shape)\n",
    "\n",
    "#assert(False)\n",
    "if USE_RGB:\n",
    "    POINT_SCALE_FACTOR = 1 # used to be 96 (img_width or height)\n",
    "else:\n",
    "    POINT_SCALE_FACTOR = 1\n",
    "points = model.predict(normalized_img)*POINT_SCALE_FACTOR\n",
    "\n",
    "\n",
    "# show test image\n",
    "plt.imshow(test_image.reshape((IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT)), cmap='gray')\n",
    "\n",
    "# show face keypoints on test image\n",
    "for x, y in zip(points[0,::2], points[0,1::2]):\n",
    "    print(x, y)\n",
    "    plt.scatter(x, y, color='r', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_images(baseline, image, alphas):\n",
    "    alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
    "    baseline_x = tf.expand_dims(baseline, axis=0)\n",
    "    input_x = tf.expand_dims(image, axis=0)\n",
    "    delta = input_x - baseline_x\n",
    "    images = baseline_x +  alphas_x * delta\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def compute_gradients(images, target_class_idx):\n",
    "    with tf.GradientTape() as tape:  # used for automatic gradient computation\n",
    "        tape.watch(images)\n",
    "        #logits = model(images)*POINT_SCALE_FACTOR\n",
    "        logits = model(images)\n",
    "        #probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n",
    "        preds = logits[:, target_class_idx]\n",
    "        #preds = tf.nn.softmax(logits/96.0, axis=-1)[:, target_class_idx]\n",
    "    return tape.gradient(preds, images)\n",
    "\n",
    "\n",
    "def predictions_and_gradients(images, target_class_idx):\n",
    "    if len(images.shape) != 4:\n",
    "        images = tf.expand_dims(images, axis=0)\n",
    "    with tf.GradientTape() as tape:  # used for automatic gradient computation\n",
    "        tape.watch(images)\n",
    "        logits = model(images)\n",
    "        probs = tf.nn.softmax(logits, axis=-1)[:, target_class_idx]\n",
    "    return probs, tape.gradient(probs, images)\n",
    "\n",
    "\n",
    "def integral_approximation(gradients):\n",
    "    # riemann_trapezoidal\n",
    "    grads = (gradients[:-1] + gradients[1:]) / tf.constant(2.0)\n",
    "    integrated_gradients = tf.math.reduce_mean(grads, axis=0)\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def integrated_gradients(baseline, image, target_class_idx, m_steps=50, batch_size=32):\n",
    "    # 1. Generate alphas.\n",
    "    alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)\n",
    "\n",
    "    # Initialize TensorArray outside loop to collect gradients.    \n",
    "    gradient_batches = tf.TensorArray(tf.float32, size=m_steps+1)\n",
    "\n",
    "    # Iterate alphas range and batch computation for speed, memory efficiency, and scaling to larger m_steps.\n",
    "    #for alpha in tf.range(0, len(alphas), batch_size):\n",
    "    for alpha in range(0, m_steps+1, batch_size):\n",
    "        from_ = alpha\n",
    "        to = tf.minimum(from_ + batch_size, m_steps+1)\n",
    "        alpha_batch = alphas[from_:to]\n",
    "        # 2. Generate interpolated inputs between baseline and input.\n",
    "        interpolated_path_input_batch = interpolate_images(baseline=baseline, image=image, alphas=alpha_batch)\n",
    "        # 3. Compute gradients between model outputs and interpolated inputs.\n",
    "        gradient_batch = compute_gradients(images=interpolated_path_input_batch, target_class_idx=target_class_idx)\n",
    "        # Write batch indices and gradients to extend TensorArray.\n",
    "        gradient_batches = gradient_batches.scatter(tf.range(from_, to), gradient_batch)    \n",
    "\n",
    "    # Stack path gradients together row-wise into single tensor.\n",
    "    total_gradients = gradient_batches.stack()\n",
    "\n",
    "    # 4. Integral approximation through averaging gradients.\n",
    "    avg_gradients = integral_approximation(gradients=total_gradients)\n",
    "\n",
    "    # 5. Scale integrated gradients with respect to input.\n",
    "    integrated_gradients = (image - baseline) * avg_gradients\n",
    "\n",
    "    return integrated_gradients\n",
    "\n",
    "\n",
    "def by_polarity(attributions, polarity):\n",
    "    if polarity == 'positive':\n",
    "        return np.clip(attributions, 0, 1)\n",
    "    elif polarity == 'negative':\n",
    "        return np.clip(attributions, -1, 0)\n",
    "    else:\n",
    "        raise Exception(\"unimplemented\")\n",
    "\n",
    "\n",
    "def ComputeThresholdByTopPercentage(attributions,\n",
    "                                    percentage=60):\n",
    "    \"\"\"Compute the threshold value that maps to the top percentage of values.\n",
    "    This function takes the cumulative sum of attributions and computes the set\n",
    "    of top attributions that contribute to the given percentage of the total sum.\n",
    "    The lowest value of this given set is returned.\n",
    "    Args:\n",
    "        attributions: (numpy.array) The provided attributions.\n",
    "        percentage: (float) Specified percentage by which to threshold.\n",
    "        plot_distribution: (bool) If true, plots the distribution of attributions\n",
    "          and indicates the threshold point by a vertical line.\n",
    "    Returns:\n",
    "        (float) The threshold value.\n",
    "    Raises:\n",
    "        ValueError: if percentage is not in [0, 100].\n",
    "    \"\"\"\n",
    "    if percentage < 0 or percentage > 100:\n",
    "        raise ValueError('percentage must be in [0, 100]')\n",
    "  \n",
    "    # For percentage equal to 100, this should in theory return the lowest\n",
    "    # value as the threshold. However, due to precision errors in numpy's cumsum,\n",
    "    # the last value won't sum to 100%. Thus, in this special case, we force the\n",
    "    # threshold to equal the min value.\n",
    "    if percentage == 100:\n",
    "        return np.min(attributions)\n",
    "\n",
    "    flat_attributions = attributions.flatten()\n",
    "    attribution_sum = np.sum(flat_attributions)\n",
    "\n",
    "    # Sort the attributions from largest to smallest.\n",
    "    sorted_attributions = np.sort(np.abs(flat_attributions))[::-1]\n",
    "\n",
    "    # Compute a normalized cumulative sum, so that each attribution is mapped to\n",
    "    # the percentage of the total sum that it and all values above it contribute.\n",
    "    cum_sum = 100.0 * np.cumsum(sorted_attributions) / attribution_sum\n",
    "    threshold_idx = np.where(cum_sum >= percentage)[0][0]\n",
    "    threshold = sorted_attributions[threshold_idx]\n",
    "\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def LinearTransform(attributions,\n",
    "                    clip_above_percentile=99.9,\n",
    "                    clip_below_percentile=70.0,\n",
    "                    low=0.2):\n",
    "    \"\"\"Transform the attributions by a linear function.\n",
    "    Transform the attributions so that the specified percentage of top attribution\n",
    "    values are mapped to a linear space between `low` and 1.0.\n",
    "    Args:\n",
    "        attributions: (numpy.array) The provided attributions.\n",
    "        percentage: (float) The percentage of top attribution values.\n",
    "        low: (float) The low end of the linear space.\n",
    "    Returns:\n",
    "        (numpy.array) The linearly transformed attributions.\n",
    "    Raises:\n",
    "        ValueError: if percentage is not in [0, 100].\n",
    "  \"\"\"\n",
    "    if clip_above_percentile < 0 or clip_above_percentile > 100:\n",
    "        raise ValueError('clip_above_percentile must be in [0, 100]')\n",
    "\n",
    "    if clip_below_percentile < 0 or clip_below_percentile > 100:\n",
    "        raise ValueError('clip_below_percentile must be in [0, 100]')\n",
    "\n",
    "    if low < 0 or low > 1:\n",
    "        raise ValueError('low must be in [0, 1]')\n",
    "\n",
    "    m = ComputeThresholdByTopPercentage(attributions,\n",
    "                                      percentage=100-clip_above_percentile)\n",
    "    e = ComputeThresholdByTopPercentage(attributions,\n",
    "                                      percentage=100-clip_below_percentile)\n",
    "\n",
    "    # Transform the attributions by a linear function f(x) = a*x + b such that\n",
    "    # f(m) = 1.0 and f(e) = low. Derivation:\n",
    "    #   a*m + b = 1, a*e + b = low  ==>  a = (1 - low) / (m - e)\n",
    "    #                               ==>  b = low - (1 - low) * e / (m - e)\n",
    "    #                               ==>  f(x) = (1 - low) (x - e) / (m - e) + low\n",
    "    transformed = (1 - low) * (np.abs(attributions) - e) / (m - e) + low\n",
    "\n",
    "    # Recover the original sign of the attributions.\n",
    "    transformed *= np.sign(attributions)\n",
    "\n",
    "    # Map values below low to 0.\n",
    "    transformed *= (transformed >= low)\n",
    "\n",
    "    # Clip values above and below.\n",
    "    transformed = np.clip(transformed, 0.0, 1.0)\n",
    "    return transformed\n",
    "\n",
    "G = [0, 255, 0]\n",
    "R = [255, 0, 0]\n",
    "def img_attributions(attributions,\n",
    "                     overlay=False,\n",
    "                     polarity='positive',\n",
    "                     clip_above_percentile=99.9,\n",
    "                     clip_below_percentile=0,\n",
    "                     positive_channel=G,\n",
    "                     negative_channel=R):\n",
    "    \n",
    "\n",
    "    # Sum of the attributions across color channels for visualization.\n",
    "    # The attribution mask shape is a grayscale image with height and width\n",
    "    # equal to the original image.\n",
    "    #attribution_mask = tf.reduce_sum(tf.math.abs(attributions), axis=-1)\n",
    "    if polarity == 'both':\n",
    "        attributions_positive = img_attributions(attributions,\n",
    "                                                      overlay=False,\n",
    "                                                      polarity='positive')\n",
    "        \n",
    "        attributions_negative = img_attributions(attributions,\n",
    "                                                      overlay=False,\n",
    "                                                      polarity='negative')\n",
    "        \n",
    "        attributions = attributions_positive + attributions_negative\n",
    "        \n",
    "        return attributions\n",
    "    elif polarity == 'positive':\n",
    "        attributions = by_polarity(attributions, polarity=polarity)\n",
    "        channel = positive_channel\n",
    "    elif polarity == 'negative':\n",
    "        attributions = by_polarity(attributions, polarity=polarity)\n",
    "        attributions = np.abs(attributions)\n",
    "        channel = negative_channel\n",
    "    else:\n",
    "        raise Exception(\"unimplemented\")\n",
    "    \n",
    "    attributions = np.average(attributions, axis=-1)\n",
    "    \n",
    "    attributions = LinearTransform(attributions,\n",
    "                                 clip_above_percentile, clip_below_percentile,\n",
    "                                 0.0)\n",
    "\n",
    "    # Convert to RGB space\n",
    "    attributions = np.expand_dims(attributions, 2) * channel\n",
    "\n",
    "    # scale the attributes to [0,255]\n",
    "    return np.clip(attributions, 0, 255).astype(int)\n",
    "\n",
    "\n",
    "def plot_img_attributions(attributions,\n",
    "                          baseline,\n",
    "                          image,\n",
    "                          cmap=None,\n",
    "                          overlay_alpha=0.4):\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
    "\n",
    "    axs[0, 0].set_title('Baseline image')\n",
    "    axs[0, 0].imshow(baseline)\n",
    "    axs[0, 0].axis('off')\n",
    "\n",
    "    axs[0, 1].set_title('Original image')\n",
    "    axs[0, 1].imshow(image, cmap='gray')\n",
    "    axs[0, 1].axis('off')\n",
    "\n",
    "    axs[1, 0].set_title('Attribution mask')\n",
    "    axs[1, 0].imshow(attributions, cmap=cmap)\n",
    "    axs[1, 0].axis('off')\n",
    "\n",
    "    axs[1, 1].set_title('Overlay')\n",
    "    axs[1, 1].imshow(attributions, cmap=cmap)\n",
    "    axs[1, 1].imshow(image, cmap='gray', alpha=overlay_alpha)\n",
    "    axs[1, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create alphas for interpolation\n",
    "m_steps = 50\n",
    "alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1) # Generate m_steps intervals for integral_approximation() below.\n",
    "\n",
    "# create baseline image, which is all black\n",
    "baseline = tf.zeros(shape=(IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT))\n",
    "# prepare test image\n",
    "test_image = test_data[image_index,:].reshape((IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT))\n",
    "test_image = normalize_image(test_image, IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT)\n",
    "test_image = tf.constant(test_image, dtype=tf.float32)  # convert to tensor\n",
    "\n",
    "# interpolate images using alphas\n",
    "interpolated_images = interpolate_images(baseline=baseline, image=test_image, alphas=alphas)\n",
    "\n",
    "# plot interpolated example images\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "i = 0\n",
    "for alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n",
    "    i += 1\n",
    "    plt.subplot(1, len(alphas[0::10]), i)\n",
    "    plt.title(f'alpha: {alpha:.1f}')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(interpolated_images)\n",
    "preds_some_keypoint_x = preds[:, 0]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(alphas, preds_some_keypoint_x)\n",
    "ax1.set_title('Target keypoint coordinate predicted over alpha')\n",
    "ax1.set_ylabel('model keypoint coordinate prediction')\n",
    "ax1.set_xlabel('alpha')\n",
    "#ax1.set_ylim([0, 1])\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "# Average across interpolation steps\n",
    "path_gradients = compute_gradients(images=interpolated_images, target_class_idx=0)\n",
    "average_grads = tf.reduce_mean(path_gradients, axis=[1, 2, 3])\n",
    "# Normalize gradients to 0 to 1 scale. E.g. (x - min(x))/(max(x)-min(x))\n",
    "average_grads_norm = (average_grads-tf.math.reduce_min(average_grads))/(tf.math.reduce_max(average_grads)-tf.reduce_min(average_grads))\n",
    "ax2.plot(alphas, average_grads_norm)\n",
    "ax2.set_title('Average pixel gradients (normalized) over alpha')\n",
    "ax2.set_ylabel('Average pixel gradients')\n",
    "ax2.set_xlabel('alpha')\n",
    "ax2.set_ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test image\n",
    "test_image = test_data[image_index,:].reshape((IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT))\n",
    "test_image = normalize_image(test_image, IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT)\n",
    "test_image = tf.constant(test_image, dtype=tf.float32)\n",
    "\n",
    "#baseline = tf.random.normal(shape=(IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT))\n",
    "#baseline = tf.random.uniform(shape=(IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT))\n",
    "baseline = tf.zeros(shape=(IMG_WIDTH, IMG_HEIGHT, INPUT_CHANNEL_COUNT))\n",
    "\n",
    "\n",
    "M_STEPS=50\n",
    "TARGET_CLASS_IDX=0\n",
    "COMBINED = False\n",
    "if COMBINED:\n",
    "#    for i in range(0, 30, 2): # step 2 for x and y attribution combination\n",
    "#        _ = plot_img_attributions_combined(image=test_image,\n",
    "#                                  baseline=baseline,\n",
    "#                                  target_class_idx=i,\n",
    "#                                  m_steps=50,\n",
    "#                                  cmap=plt.cm.inferno,\n",
    "#                                  overlay_alpha=0.4)\n",
    "    for i in range(0, 30):\n",
    "        attributions = integrated_gradients(baseline=baseline,\n",
    "                                            image=test_image,\n",
    "                                            target_class_idx=i,\n",
    "                                            m_steps=M_STEPS)\n",
    "\n",
    "        image_attributions = img_attributions(attributions,\n",
    "                                              polarity='positive')\n",
    "\n",
    "        plot_img_attributions(image_attributions,\n",
    "                              baseline=baseline,\n",
    "                              image=test_image,)\n",
    "else:\n",
    "    attributions = integrated_gradients(baseline=baseline,\n",
    "                                        image=test_image,\n",
    "                                        target_class_idx=TARGET_CLASS_IDX,\n",
    "                                        m_steps=M_STEPS)\n",
    "    \n",
    "    image_attributions = img_attributions(attributions,\n",
    "                                          polarity='positive')\n",
    "    \n",
    "    plot_img_attributions(image_attributions,\n",
    "                          baseline=baseline,\n",
    "                          image=test_image,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
